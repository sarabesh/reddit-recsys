# ğŸ§  Reddit-RecSys  
## Multimodal Recommendation System (WIP)

This project is a real-time multimodal recommendation system built on top of Reddit data. It processes image-caption pairs using **CLIP** to create joint embeddings, stores them in **Qdrant**, and supports semantic retrieval based on text or image input.

---

## ğŸ”§ Key Components

- ğŸ”„ **Ingestion**: Reddit image posts and captions pulled from multiple subreddits
- ğŸ§  **Embedding**: Featurization using `open-clip-torch`
- ğŸ—ƒï¸ **Vector Storage**: Stored and queried via [Qdrant](https://qdrant.tech)
- ğŸª„ **Orchestration**: Apache Airflow (deployed via Helm on Kubernetes)
- ğŸ” **Retrieval**: ANN-based search with image or text queries

---

> âš ï¸ **Work In Progress** â€” Setup, DAGs, and usage instructions will be added soon.
